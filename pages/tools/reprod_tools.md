---
title: Reproducibility Tools
tags:
keywords: "topic" # new keywords requiere to create a new tag file
last_updated: "June 1, 2020"
summary: 
published: true
sidebar: tools_sidebar #name of yml sidebar file withouth extension
permalink: reprod_tools.html
folder: tools
---



{% include note.html content="Please utilize the template below as a reference for your contribution. Adapt the template when deemed necessary" %}

## What is Reproducibility?

Reproducible science is science we can trust. Results, analyses, and conclusions don't shift study-to-study, computer-to-computer, or scientist-to-scientist. Of course there is natural variability in science and modeling due to randomness (e.g., random starts, random division of folds) as well as moderators and niche cases (e.g., a set of findings may differ due to biological sex). However, we want to control the things that we can control by producing science and data science in a reproducible way. There are many tools available to help us do this: R Markdown or Jupyter Notebooks make single-path, well-annotated code; repositories like the Open Science Framework offer ways to share code and data and to preregister our methods or analysis plans; and simple tips and tricks like setting seeds in code that relies on randomness. This page is dedicated to learning about why we should want to make our data science reproducible and how we can be successful in that goal.


## Recommended Path for Learning

* Begin with this paper by Simmons et al. (2011) on researcher degrees of freedom in psychological science to understand the risks of undisclosed and ever-shifting analyses (https://journals.sagepub.com/doi/pdf/10.1177/0956797611417632)
* Item 2 (video/code tutorial/document)
* Item 3 (video/code tutorial/document)

## Further Learning

## Video

* Video 1
* Video 2

## Applied papers 

* Paper 1
* Paper 2

## Online tutorials

* Online tutorial 1
* Online tutorial 2

## Theory papers 
* Paper 1
* Paper 2

{% include links.html %}
